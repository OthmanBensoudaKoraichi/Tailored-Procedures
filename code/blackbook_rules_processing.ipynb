{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "317f594c",
   "metadata": {},
   "source": [
    "# Extract all orders from markdown blackbooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9e6a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Blackbook Extraction ‚Äî ORDER LEVEL (All Files)\n",
    "Chunking ‚âà 5000 chars, extends to next Effective boundary\n",
    "Issued year priority:\n",
    "Filed > Dated > Approved > Effective\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import List, Optional\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pydantic import BaseModel\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# CONFIG\n",
    "# ============================================================\n",
    "\n",
    "LLM_MODEL = \"gpt-5-mini\"\n",
    "\n",
    "INPUT_DIR = Path(\n",
    "    \"/Users/othmanbensouda/Desktop/Orion/jobtalk_paper/files/blackbooks/md_format_clean\"\n",
    ")\n",
    "\n",
    "OUTPUT_FILE = Path(\n",
    "    \"/Users/othmanbensouda/Desktop/Orion/jobtalk_paper/files/order_extraction/extracted_orders_all_files.xlsx\"\n",
    ")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# SCHEMA\n",
    "# ============================================================\n",
    "\n",
    "class OrderEntry(BaseModel):\n",
    "    order_title: str\n",
    "    filed_date: Optional[str] = None\n",
    "    dated_date: Optional[str] = None\n",
    "    approved_date: Optional[str] = None\n",
    "    effective_date: Optional[str] = None\n",
    "\n",
    "\n",
    "class OrdersList(BaseModel):\n",
    "    orders: List[OrderEntry]\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# CHUNKING (~5000 chars, extend to next Effective boundary)\n",
    "# ============================================================\n",
    "\n",
    "def chunk_page_extend_to_effective(text: str):\n",
    "\n",
    "    text = text.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
    "\n",
    "    effective_pattern = re.compile(\n",
    "        r\"Effective\\s*:?\\s*\"\n",
    "        r\"(?:\\d{1,2}/\\d{1,2}/\\d{4}\"\n",
    "        r\"|[A-Za-z]+\\s+\\d{1,2},?\\s+\\d{4})\",\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    TARGET_SIZE = 5000\n",
    "    MAX_EXTENSION = 15000  # safety cap\n",
    "\n",
    "    chunks = []\n",
    "    i = 0\n",
    "    n = len(text)\n",
    "\n",
    "    while i < n:\n",
    "\n",
    "        tentative_end = min(i + TARGET_SIZE, n)\n",
    "\n",
    "        match = effective_pattern.search(text, tentative_end)\n",
    "\n",
    "        if match:\n",
    "            end = match.end()\n",
    "\n",
    "            # prevent runaway large chunk\n",
    "            if end - i > MAX_EXTENSION:\n",
    "                end = tentative_end\n",
    "        else:\n",
    "            end = n\n",
    "\n",
    "        chunk = text[i:end].strip()\n",
    "\n",
    "        if chunk:\n",
    "            chunks.append(chunk)\n",
    "\n",
    "        i = end\n",
    "\n",
    "    return chunks\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# PROMPT\n",
    "# ============================================================\n",
    "\n",
    "def build_prompt(chunk: str) -> str:\n",
    "    return f\"\"\"\n",
    "Extract complete court orders.\n",
    "\n",
    "An order usually contains a heading/title, and at least one date. You might retrieve an order that has no date associated.\n",
    "\n",
    "Note that an order is literally any paragraph that has a date after, such as 'AMENDING RULES 47.1, 48, AND 79, RULES OF PROCEDURE FOR THE JUVENILE COURT, ON A PERMANENT BASIS\n",
    "Filed: 12/12/2019\n",
    "Effective 12/12/2019'\n",
    "\n",
    "Additionally extract if present:\n",
    "‚Ä¢ Filed: date\n",
    "‚Ä¢ Dated: date\n",
    "‚Ä¢ Approved: date\n",
    "\n",
    "Return structured output only.\n",
    "\n",
    "TEXT:\n",
    "{chunk}\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ISSUED YEAR LOGIC (DETERMINISTIC)\n",
    "# ============================================================\n",
    "\n",
    "def extract_year(date_str):\n",
    "    if not date_str:\n",
    "        return None\n",
    "    match = re.search(r\"\\d{4}\", str(date_str))\n",
    "    return int(match.group()) if match else None\n",
    "\n",
    "\n",
    "def compute_issued_year(row):\n",
    "    for field in [\"filed_date\", \"dated_date\", \"approved_date\", \"effective_date\"]:\n",
    "        year = extract_year(row.get(field))\n",
    "        if year:\n",
    "            return year\n",
    "    return None\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# MAIN\n",
    "# ============================================================\n",
    "\n",
    "def main():\n",
    "\n",
    "    print(\"üöÄ Starting extraction (all files)\")\n",
    "\n",
    "    if not INPUT_DIR.exists():\n",
    "        print(\"‚ùå Input directory not found:\", INPUT_DIR)\n",
    "        return\n",
    "\n",
    "    md_files = sorted(INPUT_DIR.glob(\"*.md\"))\n",
    "\n",
    "    if not md_files:\n",
    "        print(\"‚ùå No markdown files found.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(md_files)} markdown files.\")\n",
    "\n",
    "    llm = ChatOpenAI(\n",
    "        model=LLM_MODEL,\n",
    "    )\n",
    "\n",
    "    structured_llm = llm.with_structured_output(OrdersList)\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # PRECOMPUTE TOTAL CHUNKS\n",
    "    # --------------------------------------------------\n",
    "\n",
    "    file_chunks_map = {}\n",
    "    total_chunks = 0\n",
    "\n",
    "    for f in md_files:\n",
    "        text = f.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "        text = re.sub(r\"<!--.*?-->\", \"\", text, flags=re.S)\n",
    "        chunks = chunk_page_extend_to_effective(text)\n",
    "\n",
    "        file_chunks_map[f] = chunks\n",
    "        total_chunks += len(chunks)\n",
    "\n",
    "    print(f\"Total chunks to process: {total_chunks}\")\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # PROCESS CHUNKS WITH GLOBAL tqdm\n",
    "    # --------------------------------------------------\n",
    "\n",
    "    all_rows = []\n",
    "\n",
    "    with tqdm(total=total_chunks, desc=\"Chunks\") as pbar:\n",
    "\n",
    "        for f, chunks in file_chunks_map.items():\n",
    "\n",
    "            if not chunks:\n",
    "                tqdm.write(f\"‚ö†Ô∏è No chunks in {f.name}\")\n",
    "                continue\n",
    "\n",
    "            for chunk in chunks:\n",
    "\n",
    "                try:\n",
    "                    result = structured_llm.invoke(build_prompt(chunk))\n",
    "                    rows = [o.model_dump() for o in result.orders]\n",
    "\n",
    "                    for r in rows:\n",
    "                        r[\"source_file\"] = f.name\n",
    "\n",
    "                    all_rows.extend(rows)\n",
    "\n",
    "                except Exception as e:\n",
    "                    tqdm.write(f\"‚ùå LLM ERROR in {f.name}: {e}\")\n",
    "\n",
    "                pbar.update(1)\n",
    "\n",
    "            # --------------------------------------------------\n",
    "            # SAVE AFTER EACH FILE\n",
    "            # --------------------------------------------------\n",
    "\n",
    "            if all_rows:\n",
    "\n",
    "                df = pd.DataFrame(all_rows)\n",
    "\n",
    "                df[\"issued_year\"] = df.apply(compute_issued_year, axis=1)\n",
    "\n",
    "                df[\"order_title_norm\"] = (\n",
    "                    df[\"order_title\"]\n",
    "                    .str.lower()\n",
    "                    .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "                    .str.strip()\n",
    "                )\n",
    "\n",
    "                df = df.drop_duplicates(\n",
    "                    subset=[\"order_title_norm\", \"effective_date\"],\n",
    "                    keep=\"first\",\n",
    "                ).drop(columns=[\"order_title_norm\"])\n",
    "\n",
    "                df.to_excel(OUTPUT_FILE, index=False)\n",
    "\n",
    "                tqdm.write(\n",
    "                    f\"üíæ Saved after {f.name} \"\n",
    "                    f\"({len(df)} total orders so far)\"\n",
    "                )\n",
    "\n",
    "    print(f\"\\n‚úÖ Finished processing all chunks.\")\n",
    "    print(f\"Final output saved to: {OUTPUT_FILE}\")\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90d4624",
   "metadata": {},
   "source": [
    "# Extract bodies of rules from orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4f0dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Blackbook Extraction ‚Äî BODY OF RULE LEVEL\n",
    "Research-grade stable version\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel\n",
    "from tqdm import tqdm\n",
    "from langchain_openai import ChatOpenAI\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import re\n",
    "\n",
    "# ============================================================\n",
    "# CONFIG\n",
    "# ============================================================\n",
    "\n",
    "LLM_MODEL = \"gpt-5\"\n",
    "MAX_WORKERS = 500   \n",
    "\n",
    "BASE_DIR = Path.cwd().parent\n",
    "\n",
    "INPUT_FILE = BASE_DIR / \"files\" / \"order_extraction\" / \"extracted_orders_all_files.xlsx\"\n",
    "OUTPUT_FILE = BASE_DIR / \"files\" / \"order_extraction\" / \"extracted_rule_bodies.xlsx\"\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# STRUCTURED OUTPUT\n",
    "# ============================================================\n",
    "\n",
    "class SplitBody(BaseModel):\n",
    "    body_segment: str   # ONLY the rule system + rule numbers\n",
    "    body_name: str      # canonical name\n",
    "\n",
    "class SplitBodiesList(BaseModel):\n",
    "    bodies: List[SplitBody]\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# METADATA EXTRACTION (DETERMINISTIC)\n",
    "# ============================================================\n",
    "\n",
    "def extract_metadata(order_title):\n",
    "    bracket = re.search(r\"\\[R-[^\\]]+\\]\", order_title)\n",
    "    bracket = bracket.group(0) if bracket else \"\"\n",
    "\n",
    "    filed = re.search(r\"Filed:\\s*[^E\\n]+\", order_title)\n",
    "    effective = re.search(r\"Effective:?\\s*.+\", order_title)\n",
    "\n",
    "    metadata_parts = []\n",
    "    for m in [bracket,\n",
    "              filed.group(0) if filed else None,\n",
    "              effective.group(0) if effective else None]:\n",
    "        if m:\n",
    "            metadata_parts.append(m.strip())\n",
    "\n",
    "    metadata = \" \".join(metadata_parts)\n",
    "\n",
    "    base_text = order_title\n",
    "    for part in metadata_parts:\n",
    "        base_text = base_text.replace(part, \"\")\n",
    "\n",
    "    return base_text.strip(), metadata\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# PROMPT (LLM ONLY SPLITS)\n",
    "# ============================================================\n",
    "\n",
    "def build_split_prompt(base_text: str) -> str:\n",
    "    return f\"\"\"\n",
    "Split this into one segment per distinct body of rules.\n",
    "\n",
    "Return:\n",
    "- body_segment: only the rule-system part with rule numbers\n",
    "- body_name: canonical name of the rule system\n",
    "\n",
    "Do NOT include bracket codes or dates.\n",
    "Do NOT rewrite wording.\n",
    "\n",
    "TEXT:\n",
    "{base_text}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# PROCESS FUNCTION\n",
    "# ============================================================\n",
    "\n",
    "def process_row(row, structured_llm):\n",
    "\n",
    "    base_text, metadata = extract_metadata(row[\"order_title\"])\n",
    "\n",
    "    try:\n",
    "        result = structured_llm.invoke(\n",
    "            build_split_prompt(base_text)\n",
    "        )\n",
    "        bodies = result.bodies\n",
    "\n",
    "        if not bodies:\n",
    "            bodies = [SplitBody(body_segment=base_text, body_name=\"Unknown\")]\n",
    "\n",
    "    except:\n",
    "        bodies = [SplitBody(body_segment=base_text, body_name=\"Unknown\")]\n",
    "\n",
    "    result_rows = []\n",
    "\n",
    "    for body in bodies:\n",
    "        new_row = row.to_dict()\n",
    "        new_row[\"order_title\"] = f\"{body.body_segment} {metadata}\".strip()\n",
    "        new_row[\"body_of_rules\"] = body.body_name\n",
    "        result_rows.append(new_row)\n",
    "\n",
    "    return result_rows\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# MAIN\n",
    "# ============================================================\n",
    "\n",
    "def main():\n",
    "\n",
    "    df = pd.read_excel(INPUT_FILE)\n",
    "\n",
    "    llm = ChatOpenAI(model=LLM_MODEL)\n",
    "    structured_llm = llm.with_structured_output(SplitBodiesList)\n",
    "\n",
    "    all_rows = []\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "\n",
    "        futures = [\n",
    "            executor.submit(process_row, row, structured_llm)\n",
    "            for _, row in df.iterrows()\n",
    "        ]\n",
    "\n",
    "        with tqdm(total=len(futures), desc=\"Orders\") as pbar:\n",
    "            for future in as_completed(futures):\n",
    "                try:\n",
    "                    all_rows.extend(future.result())\n",
    "                except Exception as e:\n",
    "                    print(\"Error:\", e)\n",
    "                pbar.update(1)\n",
    "\n",
    "    final_df = pd.DataFrame(all_rows)\n",
    "\n",
    "    # Deduplicate safely\n",
    "    final_df[\"norm\"] = (\n",
    "        final_df[\"order_title\"]\n",
    "        .str.lower()\n",
    "        .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "        .str.strip()\n",
    "    )\n",
    "\n",
    "    final_df = final_df.drop_duplicates(\n",
    "        subset=[\"norm\", \"effective_date\"],\n",
    "        keep=\"first\"\n",
    "    ).drop(columns=[\"norm\"])\n",
    "\n",
    "    OUTPUT_FILE.parent.mkdir(parents=True, exist_ok=True)\n",
    "    final_df.to_excel(OUTPUT_FILE, index=False)\n",
    "\n",
    "    print(\"Finished.\")\n",
    "    print(\"Rows:\", len(final_df))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777fe337",
   "metadata": {},
   "source": [
    "# Create an \"Issued_Date\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "734e264c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Creating issued_date column\n",
      "‚úÖ Done\n",
      "Rows: 2157\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Create issued_date column from filed_date, dated_date, approved_date, effective_date\n",
    "\"\"\"\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# ============================================================\n",
    "# CONFIG\n",
    "# ============================================================\n",
    "BASE_DIR = Path.cwd().parent  \n",
    "\n",
    "INPUT_FILE = BASE_DIR / \"files\" / \"order_extraction\" / \"extracted_rule_bodies.xlsx\"\n",
    "OUTPUT_FILE = BASE_DIR / \"files\" / \"order_extraction\" / \"extracted_rule_bodies.xlsx\"\n",
    "\n",
    "# ============================================================\n",
    "# MAIN\n",
    "# ============================================================\n",
    "def main():\n",
    "    print(\"üöÄ Creating issued_date column\")\n",
    "    \n",
    "    df = pd.read_excel(INPUT_FILE)\n",
    "    \n",
    "    # Create issued_date: use first non-null value\n",
    "    df['issued_date'] = (df['filed_date']\n",
    "                         .fillna(df['dated_date'])\n",
    "                         .fillna(df['approved_date'])\n",
    "                         .fillna(df['effective_date']))\n",
    "    \n",
    "    df.to_excel(OUTPUT_FILE, index=False)\n",
    "    \n",
    "    print(\"‚úÖ Done\")\n",
    "    print(f\"Rows: {len(df)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920b337b",
   "metadata": {},
   "source": [
    "# Categorize (local, statewide, statewide trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1257bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k7/b0_b7t6j6n72t68sh4s7t8400000gn/T/ipykernel_37375/1790392644.py:98: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  mentions_county = df[\"order_title\"].str.contains(\n",
      "/var/folders/k7/b0_b7t6j6n72t68sh4s7t8400000gn/T/ipykernel_37375/1790392644.py:104: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  mentions_trial = df[\"order_title\"].str.contains(\n",
      "LLM Classification: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2157/2157 [01:26<00:00, 24.97it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished.\n",
      "Saved to: /Users/othmanbensouda/Desktop/Orion/jobtalk_paper/files/order_extraction/extracted_rule_bodies_local_comparison.xlsx\n",
      "\n",
      "Comparison:\n",
      "Strict Local: 190\n",
      "Expanded Local: 195\n",
      "LLM Local: 77\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Step 4 Robust Version ‚Äî Deterministic + LLM Comparison\n",
    "\n",
    "Creates:\n",
    "\n",
    "Local Rule (Strict)\n",
    "Local Rule (Expanded)\n",
    "Local Rule (LLM)\n",
    "\n",
    "Statewide Rule (Strict)\n",
    "Statewide Rule (Expanded)\n",
    "Statewide Rule (LLM)\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import re\n",
    "from pydantic import BaseModel\n",
    "from langchain_openai import ChatOpenAI\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ============================================================\n",
    "# CONFIG\n",
    "# ============================================================\n",
    "\n",
    "LLM_MODEL = \"gpt-5\"\n",
    "MAX_WORKERS = 500\n",
    "\n",
    "BASE_DIR = Path.cwd().parent\n",
    "\n",
    "INPUT_FILE = BASE_DIR / \"files\" / \"order_extraction\" / \"extracted_rule_bodies.xlsx\"\n",
    "OUTPUT_FILE = BASE_DIR / \"files\" / \"order_extraction\" / \"extracted_rule_bodies_llm_regex.xlsx\"\n",
    "\n",
    "# ============================================================\n",
    "# LLM SCHEMA\n",
    "# ============================================================\n",
    "\n",
    "class LocalClassification(BaseModel):\n",
    "    is_local: int  # 1 or 0\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# LLM PROMPT\n",
    "# ============================================================\n",
    "\n",
    "def build_prompt(text: str) -> str:\n",
    "    return f\"\"\"\n",
    "Classify this court rule as either:\n",
    "\n",
    "1 = Local Rule (applies to specific county, superior court, justice court, municipal court, etc.)\n",
    "0 = Statewide Rule (applies statewide across Arizona courts)\n",
    "\n",
    "Examples of Local:\n",
    "- Rules of Practice for the Maricopa County Superior Court\n",
    "- Local Rules of Civil Procedure, Mohave County Superior Court\n",
    "\n",
    "Examples of Statewide:\n",
    "- Arizona Rules of Civil Procedure\n",
    "- Arizona Rules of Criminal Procedure\n",
    "\n",
    "Return only:\n",
    "is_local: 0 or 1\n",
    "\n",
    "TEXT:\n",
    "{text}\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# MAIN\n",
    "# ============================================================\n",
    "\n",
    "def main():\n",
    "\n",
    "    df = pd.read_excel(INPUT_FILE)\n",
    "    df[\"order_title\"] = df[\"order_title\"].astype(str)\n",
    "\n",
    "    # ============================================================\n",
    "    # STRICT DETERMINISTIC\n",
    "    # ============================================================\n",
    "\n",
    "    df[\"Local Rule (Strict)\"] = df[\"order_title\"].str.contains(\n",
    "        r\"\\blocal rules?\\b\",\n",
    "        case=False,\n",
    "        na=False\n",
    "    ).astype(int)\n",
    "\n",
    "    df[\"Statewide Rule (Strict)\"] = 1 - df[\"Local Rule (Strict)\"]\n",
    "\n",
    "    # ============================================================\n",
    "    # EXPANDED DETERMINISTIC\n",
    "    # ============================================================\n",
    "\n",
    "    county_pattern = r\"(Maricopa|Pima|Coconino|Yavapai|Mohave|Pinal|Yuma|Navajo|Gila|Cochise|Santa Cruz|La Paz|Greenlee|Graham|Apache)\"\n",
    "    trial_pattern = r\"(Superior Court|Justice Court|Municipal Court)\"\n",
    "\n",
    "    mentions_county = df[\"order_title\"].str.contains(\n",
    "        county_pattern,\n",
    "        case=False,\n",
    "        na=False\n",
    "    )\n",
    "\n",
    "    mentions_trial = df[\"order_title\"].str.contains(\n",
    "        trial_pattern,\n",
    "        case=False,\n",
    "        na=False\n",
    "    )\n",
    "\n",
    "    expanded_local = (\n",
    "        (df[\"Local Rule (Strict)\"] == 1) |\n",
    "        (mentions_county & mentions_trial)\n",
    "    )\n",
    "\n",
    "    df[\"Local Rule (Expanded)\"] = expanded_local.astype(int)\n",
    "    df[\"Statewide Rule (Expanded)\"] = 1 - df[\"Local Rule (Expanded)\"]\n",
    "\n",
    "    # ============================================================\n",
    "    # LLM CLASSIFICATION\n",
    "    # ============================================================\n",
    "\n",
    "    llm = ChatOpenAI(model=LLM_MODEL)\n",
    "    structured_llm = llm.with_structured_output(LocalClassification)\n",
    "\n",
    "    def classify(text):\n",
    "        try:\n",
    "            result = structured_llm.invoke(build_prompt(text))\n",
    "            return int(result.is_local)\n",
    "        except:\n",
    "            return 0\n",
    "\n",
    "    llm_results = []\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "        futures = [\n",
    "            executor.submit(classify, text)\n",
    "            for text in df[\"order_title\"]\n",
    "        ]\n",
    "\n",
    "        with tqdm(total=len(futures), desc=\"LLM Classification\") as pbar:\n",
    "            for future in as_completed(futures):\n",
    "                llm_results.append(future.result())\n",
    "                pbar.update(1)\n",
    "\n",
    "    # Keep original order\n",
    "    df[\"Local Rule (LLM)\"] = llm_results\n",
    "    df[\"Statewide Rule (LLM)\"] = 1 - df[\"Local Rule (LLM)\"]\n",
    "\n",
    "    # ============================================================\n",
    "    # SAVE\n",
    "    # ============================================================\n",
    "\n",
    "    OUTPUT_FILE.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_excel(OUTPUT_FILE, index=False)\n",
    "\n",
    "    print(\"\\nFinished.\")\n",
    "    print(\"Saved to:\", OUTPUT_FILE)\n",
    "\n",
    "    # Quick comparison summary\n",
    "    print(\"\\nComparison:\")\n",
    "    print(\"Strict Local:\", df[\"Local Rule (Strict)\"].sum())\n",
    "    print(\"Expanded Local:\", df[\"Local Rule (Expanded)\"].sum())\n",
    "    print(\"LLM Local:\", df[\"Local Rule (LLM)\"].sum())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
